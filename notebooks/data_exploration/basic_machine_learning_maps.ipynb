{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "french-baking",
   "metadata": {},
   "source": [
    "# Basic machine learning on maps data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limited-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from joblib import parallel_backend\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0ba763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.load(\"total_classification.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "requested-minneapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_array = np.load(\"total_classification.npy\", allow_pickle=True)\n",
    "#print(data_array.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "biblical-separate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66275212, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnb = GaussianNB()\n",
    "\n",
    "# y_pred = gnb.fit(x_train, y_train).predict(x_val)\n",
    "# print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "#       % (x_val.shape[0], (y_val != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with parallel_backend('threading', n_jobs=-1):\n",
    "#     clf = svm.SVC(kernel='linear') \n",
    "\n",
    "#     clf.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(x_val)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888745e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnb = MultinomialNB()\n",
    "# classes = np.unique(data_array[:,-1])\n",
    "\n",
    "# with parallel_backend('threading', n_jobs=-1):\n",
    "#     mnb = MultinomialNB()\n",
    "\n",
    "#     #mnb.partial_fit(x_train, y_train, classes)\n",
    "#     mnb.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = mnb.predict(x_val)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7aa56d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB accurary: 0.5331072533327825\n",
      "DecisionTreeClassifier accurary: 0.6233615735277726\n"
     ]
    }
   ],
   "source": [
    "def test_trainer(name_model, model, data):\n",
    "        with parallel_backend('threading', n_jobs=-1):\n",
    "                cross_fold = KFold(n_splits=4, random_state=1, shuffle=True)\n",
    "                accuracy = cross_val_score(model, data[\"x_train\"], data[\"y_train\"], cv=cross_fold, scoring='accuracy').mean()\n",
    "                print(f\"{name_model} accurary: {accuracy}\")\n",
    "\n",
    "models = {#'MultinomalNB': MultinomialNB(),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier()}\n",
    "\n",
    "data = {\"x_train\": data_array[:, :-1],\n",
    "        \"y_train\": data_array[:, -1]}\n",
    "\n",
    "for name, model in models.items():\n",
    "    test_trainer(name, model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4e665d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: Kmeans\n",
      "Accuracy: 0.26661370568974035\n",
      "current: GaussianNB\n",
      "Accuracy: 0.533070791738314\n",
      "current: SGDClassifier\n",
      "Accuracy: 0.36372029738871076\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 268435460\n",
    "import notebook_config as cfg\n",
    "\n",
    "def test_trainer(name_model, model, x_train, x_val, y_train, y_val, full_x):\n",
    "        with parallel_backend('threading', n_jobs=-1):\n",
    "                print(f\"current: {name_model}\")\n",
    "                #mnb.partial_fit(x_train, y_train, classes)\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                filename = f'models/{name_model}.sav'\n",
    "                pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "                y_pred = model.predict(x_val)\n",
    "                print(\"Accuracy:\", metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "                # full_pred = model.predict(full_x).reshape(16384, 16384)\n",
    "                # full_image = Image.fromarray(full_pred, mode=\"P\")\n",
    "                # full_image.putpalette(classifier.getpalette())\n",
    "                # full_image.save(f\"{name_model}.tif\")\n",
    "\n",
    "models = {#'MultinomalNB': MultinomialNB(),\n",
    "        'Kmeans': MiniBatchKMeans(n_clusters=5, random_state=0),#, batch_size=5000, max_iter=20),\n",
    "        'GaussianNB': GaussianNB(),\n",
    "        #'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "        'SGDClassifier': SGDClassifier(max_iter=100, tol=1e-3, random_state=0)\n",
    "        }\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], test_size=0.3, random_state=0)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)\n",
    "# x_val = scaler.transform(x_val)\n",
    "\n",
    "# x_train = x_train / 255\n",
    "# x_val = x_val / 255\n",
    "\n",
    "x_full = np.load(\"full_try.npy\", allow_pickle=True)[:, :-1] #scaler.transform(data_array[:, :-1])\n",
    "# print(x_full.dtype)\n",
    "# x_full = x_full.astype(\"float32\")\n",
    "# x_full = x_full / 255\n",
    "# print(x_full.dtype)\n",
    "\n",
    "classifier = Image.open(f\"{cfg.data_path}/Maps_labels.tif\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    test_trainer(name, model, x_train, x_val, y_train, y_val, x_full) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b93a7",
   "metadata": {},
   "source": [
    "Normalization seems like something that we need to do. However in out case it would be detrimental to normalize the dataset. This is because an integer between 0 and 255 can be stored in a uint8 format, while if we normalize we'll have to make use of a float32. This would mean our entire dataset would get 4 times as big in memory. In testing we found that this increase in size can cause some mayor problems.\n",
    "\n",
    "current: Kmeans \\\n",
    "Accuracy: 0.26661370568974035 \\\n",
    "current: GaussianNB \\\n",
    "Accuracy: 0.533070791738314 \\\n",
    "current: SGDClassifier \\\n",
    "Accuracy: 0.36372029738871076\n",
    "\n",
    "From these results it seems like simply using gaussian pyramids might not be enough to achief a good accuracy in the classification of pixels. The highest accuracy achieved was a measerly 53.3%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4b7534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "test = Image.open(f\"GaussianNB.tif\")\n",
    "test_array = np.array(test)\n",
    "unique_colors = np.unique(test_array)\n",
    "print(unique_colors)\n",
    "unique_colors_train = np.unique(y_train)\n",
    "print(unique_colors_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc926af",
   "metadata": {},
   "source": [
    "For some reason it seems like gaussian naive bayes never classifies anything as label 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a090c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(x_full.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c22e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\svm\\_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05310343446378796\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], test_size=0.99, random_state=0)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train = scaler.transform(x_train)\n",
    "# x_val = scaler.transform(x_val)\n",
    "\n",
    "# with parallel_backend('threading', n_jobs=-1):\n",
    "#     clf = svm.SVC(kernel='linear', max_iter=1) \n",
    "\n",
    "#     clf.fit(x_train, y_train)\n",
    "\n",
    "#     y_pred = clf.predict(x_val)\n",
    "#     print(\"Accuracy:\", metrics.accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b16ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current: DecisionTreeClassifier\n",
      "Accuracy: 0.6219942712367765\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 268435460\n",
    "import notebook_config as cfg\n",
    "\n",
    "def test_trainer(name_model, model, x_train, x_val, y_train, y_val, full_x):\n",
    "        with parallel_backend('threading', n_jobs=-1):\n",
    "                print(f\"current: {name_model}\")\n",
    "                #mnb.partial_fit(x_train, y_train, classes)\n",
    "                model.fit(x_train, y_train)\n",
    "\n",
    "                filename = f'models/{name_model}.sav'\n",
    "                pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "                y_pred = model.predict(x_val)\n",
    "                print(\"Accuracy:\", metrics.accuracy_score(y_val, y_pred))\n",
    "\n",
    "                full_pred = model.predict(full_x).reshape(16384, 16384)\n",
    "                full_image = Image.fromarray(full_pred, mode=\"P\")\n",
    "                full_image.putpalette(classifier.getpalette())\n",
    "                full_image.save(f\"{name_model}.tif\")\n",
    "\n",
    "models = {#'MultinomalNB': MultinomialNB(),\n",
    "        #'Kmeans': MiniBatchKMeans(n_clusters=5, random_state=0),#, batch_size=5000, max_iter=20),\n",
    "        #'GaussianNB': GaussianNB(),\n",
    "        'DecisionTreeClassifier': DecisionTreeClassifier()\n",
    "        #'SGDClassifier': SGDClassifier(max_iter=100, tol=1e-3, random_state=0)\n",
    "        }\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], test_size=0.3, random_state=0)\n",
    "\n",
    "x_full = np.load(\"full_try.npy\", allow_pickle=True)[:, :-1]\n",
    "\n",
    "classifier = Image.open(f\"{cfg.data_path}/Maps_labels.tif\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    test_trainer(name, model, x_train, x_val, y_train, y_val, x_full) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848a7df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_tif(model_file, model_name, data, palette):\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "    full_pred = loaded_model.predict(data).reshape(16384, 16384)\n",
    "    full_image = Image.fromarray(full_pred, mode=\"P\")\n",
    "    full_image.putpalette(palette)\n",
    "    full_image.save(f\"{model_name}.tif\")\n",
    "\n",
    "model_file = \"models/DecisionTreeClassifier.sav\"\n",
    "model_name = \"DecisionTreeClassifier\"\n",
    "data = x_full\n",
    "palette = classifier.getpalette()\n",
    "\n",
    "model_to_tif(model_file, model_name, data, palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c23c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
