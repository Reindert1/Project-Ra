{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f309f7b3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b76e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Import successfull ####\n"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pickle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "import scipy.stats as sps\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 268435460\n",
    "\n",
    "print(\"#### Import successfull ####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b072a6",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690c82d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation\n",
    "data_array = np.load(\"../../data/r4-c7_nucleus.npy\", allow_pickle=True)\n",
    "\n",
    "# Panda dataframe for using labels instead of column numbers\n",
    "dataset = pd.DataFrame(data_array, columns=['Pixel_val1', 'Pixel_val2', 'Pixel_val3', 'Pixel_val4', 'Pixel_val5',\n",
    "                                            'Pixel_val6', 'Pixel_val7', 'Pixel_val8', 'Pixel_val9', 'Gauss1',\n",
    "                                            'Gauss2', 'Gauss3', 'Gauss4', 'Label'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], random_state=0)\n",
    "\n",
    "x_train = pd.DataFrame(x_train, columns=['Pixel_val1', 'Pixel_val2', 'Pixel_val3', 'Pixel_val4', 'Pixel_val5',\n",
    "                                         'Pixel_val6', 'Pixel_val7', 'Pixel_val8', 'Pixel_val9', 'Gauss1',\n",
    "                                         'Gauss2', 'Gauss3', 'Gauss4'])\n",
    "y_train = pd.DataFrame(y_train, columns=['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f50b59",
   "metadata": {},
   "source": [
    "## Method 1: Boosting via code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b979de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating: 0\n",
      "Iterating: 1\n"
     ]
    }
   ],
   "source": [
    "class Boosting:\n",
    "\n",
    "    def __init__(self,dataset,T, test_dataset):\n",
    "        self.dataset = dataset\n",
    "        self.T = T\n",
    "        self.test_dataset = test_dataset\n",
    "        self.alphas = None\n",
    "        self.models = None\n",
    "        self.accuracy = []\n",
    "        self.predictions = None\n",
    "        \n",
    "        #print(\"initialization done...\")\n",
    "    \n",
    "    def fit(self):\n",
    "        # Set the descriptive features and the target feature\n",
    "        X = self.dataset.drop(['Label'],axis=1)\n",
    "        Y = self.dataset['Label'].where(self.dataset['Label']==1,-1)\n",
    "\n",
    "        # Initialize the weights of each sample with wi = 1/N and create a dataframe in which the evaluation is computed\n",
    "        Evaluation = pd.DataFrame(Y.copy())\n",
    "        Evaluation['weights'] = 1/len(self.dataset) # Set the initial weights w = 1/N\n",
    "        \n",
    "\n",
    "        # Run the boosting algorithm by creating T \"weighted models\"\n",
    "        \n",
    "        alphas = [] \n",
    "        models = []\n",
    "        \n",
    "        #print(\"Running fit() ....\")\n",
    "        \n",
    "        \n",
    "        for t in range(self.T):\n",
    "\n",
    "            # Training small trees on the errors of the \"\"main\"\" model\n",
    "            Tree_model = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=4, random_state=42, max_depth=2) # max depth on 1 makes a smoll tree\n",
    "\n",
    "            model = Tree_model.fit(X,Y,sample_weight=np.array(Evaluation['weights'])) \n",
    "\n",
    "            models.append(model)\n",
    "            predictions = model.predict(X)\n",
    "            score = model.score(X,Y)\n",
    "\n",
    "            # Add values to the Evaluation DataFrame\n",
    "            Evaluation['predictions'] = predictions\n",
    "            Evaluation['evaluation'] = np.where(Evaluation['predictions'] == Evaluation['Label'],1,0)\n",
    "            Evaluation['misclassified'] = np.where(Evaluation['predictions'] != Evaluation['Label'],1,0)\n",
    "\n",
    "            # Calculate the misclassification rate and accuracy\n",
    "            accuracy = sum(Evaluation['evaluation'])/len(Evaluation['evaluation'])\n",
    "            misclassification = sum(Evaluation['misclassified'])/len(Evaluation['misclassified'])\n",
    "\n",
    "\n",
    "            # Caclulate the error\n",
    "            err = np.sum(Evaluation['weights']*Evaluation['misclassified'])/np.sum(Evaluation['weights'])\n",
    " \n",
    "   \n",
    "            # Calculate the alpha values\n",
    "            alpha = np.log((1-err)/err)\n",
    "            alphas.append(alpha)\n",
    "\n",
    "\n",
    "            Evaluation['weights'] *= np.exp(alpha*Evaluation['misclassified'])\n",
    "\n",
    "            print(\"Running iteration:\", t)\n",
    "            print(\"Learning rate:\", alpha)\n",
    "            print('The Accuracy of the {0}. model is : '.format(t+1), accuracy * 100,'%')\n",
    "            print('The missclassification rate is: ', misclassification * 100,'%')\n",
    "        \n",
    "        self.alphas = alphas\n",
    "        self.models = models\n",
    "            \n",
    "    def predict(self):\n",
    "        X_test = self.test_dataset.drop(['Label'],axis=1).reindex(range(len(x_train)))\n",
    "        Y_test = self.test_dataset['Label'].reindex(range(len(y_train))).where(self.dataset['Label']==1,-1)\n",
    "    \n",
    "        accuracy = []\n",
    "        predictions = []\n",
    "        \n",
    "        for alpha, model in zip(self.alphas,self.models):\n",
    "            prediction = alpha * model.predict(X_test)\n",
    "            predictions.append(prediction)\n",
    "            self.accuracy.append(np.sum(np.sign(np.sum(np.array(predictions),axis=0))==Y_test.values)/len(predictions[0]))\n",
    "        self.predictions = np.sign(np.sum(np.array(predictions),axis=0))\n",
    "\n",
    "        \n",
    "## Finalizing stage:\n",
    "\n",
    "number_of_base_learners = 3\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "\n",
    "for i in range(number_of_base_learners):\n",
    "    print(\"Iterating:\", i)\n",
    "    model = Boosting(dataset, i, dataset)\n",
    "    model.fit()\n",
    "    model.predict()\n",
    "\n",
    "print(\"\\n#### DONE ####\")\n",
    "ax0.plot(range(len(model.accuracy)), model.accuracy, '-b')\n",
    "ax0.set_xlabel('# models used for Boosting ')\n",
    "ax0.set_ylabel('accuracy')\n",
    "print('With a number of ', number_of_base_learners, 'base models we receive an accuracy of ', model.accuracy[-1] * 100,\n",
    "      '%')\n",
    "\n",
    "plt.savefig('../../data/result_graph_nucleus.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f7a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "889afe68",
   "metadata": {},
   "source": [
    "## Method 2: Boosting with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc55ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "data_array = np.load(\"../../data/r4-c7_nucleus.npy\", allow_pickle=True)\n",
    "print(\"Shape:\", data_array.shape)\n",
    "\n",
    "dataset = pd.DataFrame(data_array, columns=['Pixel_val1', 'Pixel_val2', 'Pixel_val3', 'Pixel_val4', 'Pixel_val5',\n",
    "                                            'Pixel_val6', 'Pixel_val7', 'Pixel_val8', 'Pixel_val9', 'Gauss1',\n",
    "                                            'Gauss2', 'Gauss3', 'Gauss4', 'Label'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(data_array[:, :-1], data_array[:, -1], random_state=0)\n",
    "\n",
    "for label in dataset.columns:\n",
    "    print(\"Running:\", label)\n",
    "    dataset[label] = LabelEncoder().fit(dataset[label]).transform(dataset[label])\n",
    "    \n",
    "X = dataset.drop(['Label'],axis=1)\n",
    "Y = dataset['Label']\n",
    "\n",
    "# model = DecisionTreeClassifier(criterion='entropy',max_depth=1)\n",
    "# AdaBoost = AdaBoostClassifier(base_estimator= model,n_estimators=4,learning_rate=1)\n",
    "\n",
    "print(\"Initializing booster...\")\n",
    "AdaBoost = AdaBoostClassifier(n_estimators=5, learning_rate=0.1, algorithm='SAMME')\n",
    "\n",
    "print(\"Fitting...\")\n",
    "AdaBoost.fit(X,Y)\n",
    "\n",
    "prediction = AdaBoost.score(X,Y)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
